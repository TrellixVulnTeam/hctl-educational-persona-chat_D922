params:
  model : gpt2
  max_history: 2
  no_sample : True
  max_length: 20
  device: cuda
  min_length: 1
  seed: 0
  temperature: 0.9
  top_k: 0
  top_p: 0.9

files:
  dataset_cache: ${hydra:runtime.cwd}/situationchat_original(augmented)_dataset_cache_GPT2Tokenizer
  dataset_path: ${hydra:runtime.cwd}/data/situationchat_original(augmented).json
  model_checkpoint: ${hydra:runtime.cwd}/runs/Jan12_15-04-08_sitaution_original_gpt2

setting:
  situation: ""
